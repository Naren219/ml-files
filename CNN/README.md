### activation functions
* relu doesn't suffer from over-saturations when values are near the min/max


### Links
https://colab.research.google.com/drive/1hmcnrzM-IU9kFaIxaDgmOHxZ-zEJYhQn?usp=sharing